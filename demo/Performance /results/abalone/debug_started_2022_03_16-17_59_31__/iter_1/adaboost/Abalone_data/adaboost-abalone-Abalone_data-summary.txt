Classification on abalone for Abalone_data with adaboost.

Database configuration : 
	- Database name : abalone
	- View name : Abalone_data	 View shape : (4177, 8)
	- Learning Rate : 0.7498204452956667
	- Labels used : <10, >=10
	- Number of cross validation folds : 7

Classifier configuration : 
	- Adaboost with n_estimators : 63, base_estimator : DecisionTreeClassifier
	- Executed on 6 core(s) 


	For Accuracy score using {}, (higher is better) : 
		- Score on train : 0.830779054916986
		- Score on test : 0.7722488038277512

	For F1 score using average: micro, {} (higher is better) : 
		- Score on train : 0.830779054916986
		- Score on test : 0.7722488038277512

	For Balanced accuracy score using {}, (higher is better) : 
		- Score on train : 0.8308524173027989
		- Score on test : 0.7722853877598863

Test set confusion matrix : 

╒══════╤═══════╤════════╕
│      │   <10 │   >=10 │
╞══════╪═══════╪════════╡
│ <10  │   398 │    126 │
├──────┼───────┼────────┤
│ >=10 │   112 │    409 │
╘══════╧═══════╧════════╛



 Classification took 0:00:49

 Classifier Interpretation : 
Feature importances : 
- Feature index : 7, feature importance : 0.3275046557263553
- Feature index : 5, feature importance : 0.17263117274996814
- Feature index : 6, feature importance : 0.13420674702348245
- Feature index : 2, feature importance : 0.11207903241352003
- Feature index : 4, feature importance : 0.11132717477151537
- Feature index : 3, feature importance : 0.05783627621728696
- Feature index : 0, feature importance : 0.04873223094427606
- Feature index : 1, feature importance : 0.0356827101535957


 Estimator error | Estimator weight
0.2081736909323117 | 0.10932808458501567
0.2946504551751435 | 0.0714334488720406
0.373340061944236 | 0.04238314667806824
0.374428964251112 | 0.042002490838206286
0.3988507519377019 | 0.03357300008119824
0.44670651981105947 | 0.017511451117546074
0.4375011257102882 | 0.020565761084351653
0.4336438722891388 | 0.02184970827639154
0.41921732128371053 | 0.026676926977875774
0.4161582837987321 | 0.027706160528008787
0.42698564664844574 | 0.024072402038814715
0.44552771774033817 | 0.017901850875962036
0.47751156619142177 | 0.007366269005279014
0.47269005587541535 | 0.008948464350538515
0.4698006922277359 | 0.009897401440229131
0.4498376653601759 | 0.016475418647551646
0.45531955057559526 | 0.01466468751613075
0.47767249243180376 | 0.007313485859141007
0.4633884830446513 | 0.012005796167935495
0.46619846075472776 | 0.011081400517597526
0.4779390977955982 | 0.007226043734626778
0.4711320955255765 | 0.009460057589893826
0.47239775151271524 | 0.00904443580958345
0.4727696915597871 | 0.00892231886135311
0.46206977835453455 | 0.012439869338147435
0.4668366955469468 | 0.010871541479673527
0.47637335024130817 | 0.007739643519852011
0.4741845018782753 | 0.008457891778418571
0.4541230393788728 | 0.015059588686553549
0.4369542145039757 | 0.020747652315589754
0.42518591707059805 | 0.024674682838475296
0.4440458495838888 | 0.018392909680330298
0.4432313161501821 | 0.018662968255492955
0.4626192305293244 | 0.01225898730912345
0.48829444265497335 | 0.0038323637031991075
0.4884206261748156 | 0.0037910367457643355
0.488660363047879 | 0.0037125207232029138
0.48891183458834553 | 0.003630163324840886
0.4891234902569631 | 0.00356084712498604
0.4911497886150145 | 0.002897305329520238
0.4652360082033879 | 0.011397935168278325
0.4527722481264457 | 0.01550561950090077
0.45386978512430703 | 0.01514319596967
0.4538535913450444 | 0.015148542318799751
0.4564302586249174 | 0.014298257592941992
0.4557872148234473 | 0.014510384330675372
0.4510923255707395 | 0.016060650666377185
0.4534943205570734 | 0.015267163280751084
0.450560601357875 | 0.01623640366595393
0.4656203971932006 | 0.011271505938766364
0.4678554631560981 | 0.010536632479507
0.45509710616656773 | 0.01473809090511586
0.44847592194954333 | 0.01692582536906905
0.45599695912029353 | 0.014441188752937461
0.47720017568670753 | 0.007468408170366751
0.484753655841156 | 0.004992242071331713
0.4810748450220936 | 0.006197866679081273
0.4818198202907336 | 0.0059536723650682
0.48264806085731193 | 0.0056822156966775585
0.48589125340312517 | 0.004619542835141171
0.48396270116868984 | 0.005251404585359247
0.484694644703254 | 0.005011576654425679
0.4841150283024479 | 0.0052014913962942794