Classification on abalone for Abalone_data with adaboost.

Database configuration : 
	- Database name : abalone
	- View name : Abalone_data	 View shape : (4177, 8)
	- Learning Rate : 0.7498204452956667
	- Labels used : <10, >=10
	- Number of cross validation folds : 7

Classifier configuration : 
	- Adaboost with n_estimators : 78, base_estimator : DecisionTreeClassifier
	- Executed on 6 core(s) 


	For Accuracy score using {}, (higher is better) : 
		- Score on train : 0.8065134099616859
		- Score on test : 0.7827751196172249

	For F1 score using average: micro, {} (higher is better) : 
		- Score on train : 0.8065134099616859
		- Score on test : 0.7827751196172249

	For Balanced accuracy score using {}, (higher is better) : 
		- Score on train : 0.8064591896652965
		- Score on test : 0.7826771768911811

Test set confusion matrix : 

╒══════╤═══════╤════════╕
│      │   <10 │   >=10 │
╞══════╪═══════╪════════╡
│ <10  │   428 │     96 │
├──────┼───────┼────────┤
│ >=10 │   131 │    390 │
╘══════╧═══════╧════════╛



 Classification took 0:00:52

 Classifier Interpretation : 
Feature importances : 
- Feature index : 7, feature importance : 0.39271595206975435
- Feature index : 2, feature importance : 0.16127580697845922
- Feature index : 5, feature importance : 0.15292935335239724
- Feature index : 4, feature importance : 0.10114344296497825
- Feature index : 3, feature importance : 0.07481307210716921
- Feature index : 6, feature importance : 0.07219136359832387
- Feature index : 0, feature importance : 0.029263976797518312
- Feature index : 1, feature importance : 0.015667032131399052


 Estimator error | Estimator weight
0.24521072796934876 | 0.11767608403691841
0.29123043570219975 | 0.0930899461783184
0.34821927235637273 | 0.06561143604221022
0.3885532366937051 | 0.04745449272587636
0.4210710596223639 | 0.033322782330493364
0.4621764655664594 | 0.015865384361274052
0.4435517660807635 | 0.023733607720617084
0.43838634230265683 | 0.02592673661019812
0.4433026019566624 | 0.023839274686646407
0.4633343215487239 | 0.01537793532942589
0.4597907197260027 | 0.01687031385744065
0.46313544477885243 | 0.015461649031019592
0.4657819395772068 | 0.014348046941980608
0.4548062260833945 | 0.018972455635996137
0.4661519378132404 | 0.01419242370375422
0.4653199158490788 | 0.014542398850669104
0.4767818408370764 | 0.00972743305499274
0.48449477039223166 | 0.0064934497841131495
0.48499937369537727 | 0.006281997449023278
0.4854489680264688 | 0.006093607250026809
0.4858354396007684 | 0.005931674812926459
0.48481822491063853 | 0.00635790574738787
0.48291664224755637 | 0.007154846621673004
0.4847039063641537 | 0.006405810468178145
0.4816609716271817 | 0.007681202221124583
0.46961652355960665 | 0.012735936837858801
0.4821728636620255 | 0.007466614509252484
0.47214914195191177 | 0.011672028988111788
0.4754474968547694 | 0.010287343132160462
0.4799683643572635 | 0.008390869072262648
0.47777582401939533 | 0.00931043412326877
0.48376241138916665 | 0.006800366070701795
0.48319785417385763 | 0.007036980032595443
0.48357847940567555 | 0.0068774526449662836
0.4869643120325082 | 0.005458714718375512
0.4736827372361594 | 0.01102808914539598
0.4745675334361059 | 0.010656668540534755
0.46494468450254134 | 0.014700259644965083
0.47509537908076405 | 0.010435121058506717
0.4828427813589127 | 0.007185805271779583
0.4743724230999275 | 0.010738566302946116
0.4786685750349038 | 0.008935967459633206
0.4828013738461193 | 0.007203161288887027
0.4891032305679055 | 0.004562727652025856
0.48973789966202846 | 0.0042969001571060966
0.4898684257592796 | 0.004242231799040575
0.4896574585476975 | 0.004330591669920068
0.4893629433992782 | 0.004453946698383204
0.4906792879256773 | 0.0039026303687183105
0.49219976479313554 | 0.003265885449993097
0.49021634017530047 | 0.004096517309907465
0.49069756569904704 | 0.003894975602165674
0.4928828242002317 | 0.0029798543791952022
0.4925870442651405 | 0.003103710774304135
0.4923490551477516 | 0.0032033691218851675
0.488429632003138 | 0.004844876647061007
0.48050885051910264 | 0.008164236903061445
0.49061709694255945 | 0.003928676150049635
0.4922323397136247 | 0.0032522444362597307
0.49094027512783095 | 0.0037933294072718744
0.49110151085469966 | 0.003725805217991678
0.4913887870964403 | 0.0036054982153786975
0.4796381736094917 | 0.008529331555672431
0.4496805010235331 | 0.02113815145828373
0.4546990172919858 | 0.01901770991255229
0.48495031629808166 | 0.0063025542187730025
0.48825464423432163 | 0.004918176291569097
0.48444785218827435 | 0.0065131113678971245
0.48530543529243997 | 0.006153749626816161
0.49224179528154943 | 0.0032482848452206003
0.49344838695605586 | 0.002743033487912204
0.49388572289939786 | 0.0025599104895431164
0.49416580774404556 | 0.0024426343553753467
0.4938828158837631 | 0.002561127713132299
0.49406859898524247 | 0.002483337085095848
0.4812865219797724 | 0.007838183588421182
0.46170297456361675 | 0.016064769849755276
0.4417342937961944 | 0.02450465189977363