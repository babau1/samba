Classification on pima for pima with adaboost.

Database configuration : 
	- Database name : pima
	- View name : pima	 View shape : (768, 8)
	- Learning Rate : 0.75
	- Labels used : No, Yes
	- Number of cross validation folds : 7

Classifier configuration : 
	- Adaboost with n_estimators : 77, base_estimator : DecisionTreeClassifier
	- Executed on 6 core(s) 


	For Accuracy score using {}, (higher is better) : 
		- Score on train : 0.8819444444444444
		- Score on test : 0.7552083333333334

	For F1 score using average: micro, {} (higher is better) : 
		- Score on train : 0.8819444444444444
		- Score on test : 0.7552083333333334

	For Balanced accuracy score using {}, (higher is better) : 
		- Score on train : 0.8631641791044776
		- Score on test : 0.715044776119403

Test set confusion matrix : 

╒═════╤══════╤═══════╕
│     │   No │   Yes │
╞═════╪══════╪═══════╡
│ No  │  106 │    19 │
├─────┼──────┼───────┤
│ Yes │   28 │    39 │
╘═════╧══════╧═══════╛



 Classification took 0:00:26

 Classifier Interpretation : 
Feature importances : 
- Feature index : 1, feature importance : 0.2802450169220767
- Feature index : 5, feature importance : 0.25040641585537027
- Feature index : 7, feature importance : 0.18377357962837737
- Feature index : 6, feature importance : 0.11035514858527075
- Feature index : 4, feature importance : 0.05902108423642441
- Feature index : 0, feature importance : 0.04566955475263973
- Feature index : 3, feature importance : 0.03734447300751036
- Feature index : 2, feature importance : 0.033184727012330516


 Estimator error | Estimator weight
0.2291666666666666 | 0.06821949934979499
0.31306306306306303 | 0.044194941208118635
0.3755481456861337 | 0.02859696516413117
0.35946898713044184 | 0.03248771446684195
0.3564032604082121 | 0.033237939054814994
0.3918206453999689 | 0.024726471125403705
0.39887389683191404 | 0.023067063289111026
0.40583628196365124 | 0.021438692163723756
0.4317490635206038 | 0.015449969519862083
0.4132165967081464 | 0.019722201841165316
0.40671727393830215 | 0.021233289689001275
0.3981872440712967 | 0.023228165564956223
0.4472395893910727 | 0.011913174826402648
0.4420032603127772 | 0.013105765101532905
0.39801833033376754 | 0.023267810439466123
0.46636239678373254 | 0.0075784631539083935
0.41798961353282554 | 0.01861697939597208
0.4505788774326619 | 0.011154049412817687
0.45010209367331283 | 0.011262373831688632
0.44904291640266353 | 0.011503091840393017
0.45372860739981236 | 0.010438944737119853
0.4477754518943817 | 0.01179128531820139
0.46860801172200794 | 0.0070711500195943374
0.4584995012153279 | 0.009357357622332092
0.44713675734143377 | 0.011936568610642927
0.4542564746249712 | 0.010319183280927492
0.4534280203256287 | 0.010507151859417526
0.4600814680486697 | 0.008999107861231714
0.4610675258522097 | 0.008775899335419656
0.4655535817977589 | 0.007761259168445562
0.47907722998702024 | 0.004709474792950459
0.47991758930747214 | 0.00452011159250558
0.4806930495247986 | 0.004345395236391894
0.4029856433200807 | 0.022104292573396158
0.4359178272056999 | 0.014495455303603966
0.45305376599621894 | 0.010592085817471515
0.4275247071509826 | 0.016419474461012086
0.44977263683883273 | 0.011337237991251992
0.45183516135447965 | 0.010868722151907354
0.4381587875441982 | 0.01398321207214095
0.4108426755678651 | 0.020273292395803513
0.44583606816798316 | 0.012232558497393424
0.4362901645407862 | 0.014410304814674842
0.4266319293758025 | 0.016624675869696473
0.47594113409238836 | 0.005416394361382922
0.4759057077652065 | 0.005424382285334016
0.47320877681825446 | 0.006032652426977511
0.4768254510473498 | 0.005217016161620921
0.4804635500456883 | 0.004397100777448647
0.47792021986556055 | 0.004970234698798397
0.4756324829633964 | 0.005485990823449133
0.47789488030030347 | 0.004975946163228418
0.48106068349337927 | 0.004262572227163836
0.4431066832908589 | 0.01285422191248799
0.44455434832588453 | 0.012524396804021704
0.46087195874264564 | 0.008820163256212196
0.459817099580763 | 0.009058963461782817
0.47781599992894636 | 0.004993725734181216
0.47875844523383027 | 0.004781315394184821
0.4796240777697599 | 0.0045862473408144755
0.4800710983871236 | 0.004485523269553685
0.4821305630992274 | 0.004021568640310041
0.48230517980669535 | 0.003982237633617193
0.48108869054199915 | 0.004256262804742306
0.4550450901349624 | 0.010140307150183834
0.4735824982842305 | 0.005948342447901977
0.46078816709622106 | 0.008839129174459833
0.48490336805410605 | 0.003397126383911553
0.4709006184171707 | 0.006553516929184711
0.4468765823344029 | 0.01199576174132381
0.44051904722555524 | 0.01344432199151895
0.4337923498770942 | 0.014981854032620439
0.406006737032331 | 0.02139893973633247
0.4137234907699104 | 0.0196046518448642
0.45638927100117105 | 0.009835533388948534
0.4643609846873874 | 0.00803086673301408
0.467134902880452 | 0.007403910445784277