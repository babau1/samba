Classification on pima for pima with decision_tree.

Database configuration : 
	- Database name : pima
	- View name : pima	 View shape : (768, 8)
	- Learning Rate : 0.75
	- Labels used : No, Yes
	- Number of cross validation folds : 7

Classifier configuration : 
	- DecisionTree with max_depth : 7, criterion : entropy, splitter : random, random_state : RandomState(MT19937)
	- Executed on 6 core(s) 


	For Accuracy score using {}, (higher is better) : 
		- Score on train : 0.8246527777777778
		- Score on test : 0.703125

	For F1 score using average: micro, {} (higher is better) : 
		- Score on train : 0.8246527777777778
		- Score on test : 0.703125

	For Balanced accuracy score using {}, (higher is better) : 
		- Score on train : 0.767223880597015
		- Score on test : 0.6127164179104478

Test set confusion matrix : 

╒═════╤══════╤═══════╕
│     │   No │   Yes │
╞═════╪══════╪═══════╡
│ No  │  114 │    11 │
├─────┼──────┼───────┤
│ Yes │   46 │    21 │
╘═════╧══════╧═══════╛



 Classification took 0:00:01

 Classifier Interpretation : 
First featrue : 
	1 <= 155.15563844710385
Feature importances : 
- Feature index : 1, feature importance : 0.4639367126472841
- Feature index : 7, feature importance : 0.17939602139478444
- Feature index : 5, feature importance : 0.13323517330611384
- Feature index : 2, feature importance : 0.05910661999829912
- Feature index : 3, feature importance : 0.052617422010486865
- Feature index : 6, feature importance : 0.03752495827554373
- Feature index : 0, feature importance : 0.03723531415253639
- Feature index : 4, feature importance : 0.03694777821495143
