Classification on pima for pima with adaboost.

Database configuration : 
	- Database name : pima
	- View name : pima	 View shape : (768, 8)
	- Learning Rate : 0.75
	- Labels used : No, Yes
	- Number of cross validation folds : 7

Classifier configuration : 
	- Adaboost with n_estimators : 30, base_estimator : DecisionTreeClassifier
	- Executed on 6 core(s) 


	For Accuracy score using {}, (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.6822916666666666

	For F1 score using average: micro, {} (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.6822916666666666

	For Balanced accuracy score using {}, (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.6521194029850746

Test set confusion matrix : 

╒═════╤══════╤═══════╕
│     │   No │   Yes │
╞═════╪══════╪═══════╡
│ No  │   94 │    31 │
├─────┼──────┼───────┤
│ Yes │   30 │    37 │
╘═════╧══════╧═══════╛



 Classification took 0:00:23

 Classifier Interpretation : 
Feature importances : 
- Feature index : 6, feature importance : 0.1892732805222287
- Feature index : 5, feature importance : 0.18471651969679784
- Feature index : 1, feature importance : 0.17264833943895191
- Feature index : 7, feature importance : 0.10959534801628097
- Feature index : 2, feature importance : 0.10325986814025809
- Feature index : 3, feature importance : 0.08348287933018975
- Feature index : 4, feature importance : 0.08049742467101523
- Feature index : 0, feature importance : 0.07652634018427756


 Estimator error | Estimator weight
0.15451388888888887 | 0.0463836146350835
0.19466811249798124 | 0.03875130948339547
0.21830307671984198 | 0.03481123335126777
0.17332254318392165 | 0.04263479523559083
0.23146501436447053 | 0.032750111055226926
0.29477939767206074 | 0.02380501063717905
0.26758024266155 | 0.027479695006739822
0.318907784528461 | 0.020707880537412963
0.28137869778811847 | 0.025588433255849294
0.23281318738098244 | 0.03254370305872333
0.18983382201833882 | 0.03960091490105326
0.31664579925086767 | 0.020992623671899083
0.2485197576676971 | 0.030197504287465156
0.18674616802944316 | 0.04015225459057311
0.22592990017524825 | 0.03360649406062473
0.229551618454932 | 0.0330445037697787
0.3343905826710266 | 0.018786566862795735
0.18866997741105374 | 0.03980791984157392
0.22757673475252027 | 0.033350169305622276
0.19197822546709523 | 0.03922203425954259
0.19613269443032672 | 0.038497082970380306
0.2224435841461925 | 0.03415353188922625
0.19372588934327142 | 0.03891563077746274
0.2042812610139998 | 0.03710814169311347
0.21674226163882282 | 0.03506149104015219
0.2540350410986545 | 0.029397453073423292
0.2910667389575745 | 0.02429420333335394
0.2697758573496588 | 0.027174745481139788
0.19157067955358648 | 0.039293791235283766
0.17728303272796764 | 0.04188715669906694