Classification on pima for pima with adaboost.

Database configuration : 
	- Database name : pima
	- View name : pima	 View shape : (768, 8)
	- Learning Rate : 0.75
	- Labels used : No, Yes
	- Number of cross validation folds : 7

Classifier configuration : 
	- Adaboost with n_estimators : 33, base_estimator : DecisionTreeClassifier
	- Executed on 6 core(s) 


	For Accuracy score using {}, (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.7135416666666666

	For F1 score using average: micro, {} (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.7135416666666666

	For Balanced accuracy score using {}, (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.7038208955223881

Test set confusion matrix : 

╒═════╤══════╤═══════╕
│     │   No │   Yes │
╞═════╪══════╪═══════╡
│ No  │   92 │    33 │
├─────┼──────┼───────┤
│ Yes │   22 │    45 │
╘═════╧══════╧═══════╛



 Classification took 0:00:27

 Classifier Interpretation : 
Feature importances : 
- Feature index : 1, feature importance : 0.19746586880754702
- Feature index : 6, feature importance : 0.19074855466220908
- Feature index : 5, feature importance : 0.16730241408207028
- Feature index : 7, feature importance : 0.11086758061619251
- Feature index : 2, feature importance : 0.10492887838737887
- Feature index : 0, feature importance : 0.0857172234401422
- Feature index : 4, feature importance : 0.07246704841261539
- Feature index : 3, feature importance : 0.07050243159184454


 Estimator error | Estimator weight
0.13541666666666666 | 0.04464410131971953
0.20366079703429102 | 0.03283651590075294
0.2146865034403873 | 0.031231131029142743
0.2704121610904195 | 0.023901466378025493
0.20433303225916946 | 0.03273682326830557
0.27237163301036604 | 0.02366283395737501
0.23995604238422757 | 0.02776381868799797
0.2623927579566602 | 0.024889680356531853
0.21865062539009736 | 0.03066866659488734
0.22018290284218645 | 0.030453224966181244
0.20083991891977626 | 0.033257546774033475
0.25536852789665326 | 0.02577136121518209
0.2698643805730742 | 0.02396837156966615
0.19745669579908764 | 0.03376839306787547
0.20227556753969667 | 0.03304272095451872
0.18573591797522512 | 0.03559116291357683
0.2897179019426167 | 0.021595009635059
0.21906541268578378 | 0.030610239682331786
0.20876045512518757 | 0.03208623749428577
0.21517193933812448 | 0.03116185107536395
0.2141029468001527 | 0.031314565318976265
0.282757687405874 | 0.022415433323722908
0.22675500136846483 | 0.029541145312627675
0.21354191684750315 | 0.03139493498542258
0.18172973827267144 | 0.03623445079779032
0.26112554181025843 | 0.02504759821208481
0.26897572624418664 | 0.02407709304274935
0.28314719856019305 | 0.022369201782363454
0.19461849784145402 | 0.034202057287518205
0.22102346490210234 | 0.030335497003299575
0.20153263956200515 | 0.033153747472026734
0.15677341768521422 | 0.040515192121671074
0.18469086883134928 | 0.03575792649893404