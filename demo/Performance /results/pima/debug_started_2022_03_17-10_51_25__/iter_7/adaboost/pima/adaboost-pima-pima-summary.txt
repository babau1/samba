Classification on pima for pima with adaboost.

Database configuration : 
	- Database name : pima
	- View name : pima	 View shape : (768, 8)
	- Learning Rate : 0.75
	- Labels used : No, Yes
	- Number of cross validation folds : 7

Classifier configuration : 
	- Adaboost with n_estimators : 75, base_estimator : DecisionTreeClassifier
	- Executed on 6 core(s) 


	For Accuracy score using {}, (higher is better) : 
		- Score on train : 0.9027777777777778
		- Score on test : 0.6875

	For F1 score using average: micro, {} (higher is better) : 
		- Score on train : 0.9027777777777778
		- Score on test : 0.6875

	For Balanced accuracy score using {}, (higher is better) : 
		- Score on train : 0.8814726368159204
		- Score on test : 0.6561194029850747

Test set confusion matrix : 

╒═════╤══════╤═══════╕
│     │   No │   Yes │
╞═════╪══════╪═══════╡
│ No  │   95 │    30 │
├─────┼──────┼───────┤
│ Yes │   30 │    37 │
╘═════╧══════╧═══════╛



 Classification took 0:00:26

 Classifier Interpretation : 
Feature importances : 
- Feature index : 5, feature importance : 0.23365238986422357
- Feature index : 1, feature importance : 0.22091726953234214
- Feature index : 6, feature importance : 0.17842885563290894
- Feature index : 7, feature importance : 0.12595310920825814
- Feature index : 0, feature importance : 0.08382778255704672
- Feature index : 4, feature importance : 0.06768734729423946
- Feature index : 2, feature importance : 0.061239284374686044
- Feature index : 3, feature importance : 0.028293961536294914


 Estimator error | Estimator weight
0.21701388888888884 | 0.07022796660437067
0.35616851441241687 | 0.03240241633031511
0.32678587538502174 | 0.039557108230671496
0.38296784504464493 | 0.02610493452658078
0.37159694288292977 | 0.028754006220163164
0.3782282629598166 | 0.027205299226722383
0.38276535833334785 | 0.02615183761570413
0.41223506015820943 | 0.019414826297396177
0.39660349927444954 | 0.02296707694065666
0.43618808194254527 | 0.014046494511302712
0.457757851720345 | 0.009269875840788358
0.460727941265498 | 0.008615303531882964
0.4310263326730569 | 0.01519681365922293
0.4472362889080786 | 0.011594358129843524
0.46271083908371435 | 0.00817864141253816
0.47036818215079107 | 0.006494697807312077
0.46106910383421057 | 0.008540155605456953
0.4011882720333724 | 0.021920566132937833
0.45654477440616015 | 0.009537411320697388
0.4488890564413573 | 0.011228582214863836
0.4397823088432241 | 0.013247338136716759
0.4472987710790087 | 0.011580525485562838
0.47479451392347694 | 0.005522742652223966
0.4676266224778023 | 0.0070972063041260395
0.4446637535751461 | 0.01216420567082573
0.47073369276787347 | 0.006414400563948862
0.4729182679709584 | 0.005934622638495408
0.4505235602851985 | 0.010867093881609053
0.4418188526929739 | 0.012795152268251503
0.4432642212094806 | 0.01247449299276698
0.463626553558134 | 0.007977076646772531
0.45208258333150353 | 0.01052251906627993
0.43120259404923894 | 0.015157479386695734
0.41921231244520585 | 0.01784265115591217
0.44895460411994614 | 0.011214080985212437
0.4252423974484015 | 0.01648977679118742
0.46012487030575994 | 0.008748161928239287
0.46741152784271967 | 0.007144495033172233
0.45600126121430606 | 0.009657315938232047
0.4687091896558502 | 0.006859242833114191
0.44461861079900494 | 0.012174211114562078
0.45786686922573355 | 0.009245838270805641
0.45752277331648544 | 0.009321711963905834
0.4780505346995527 | 0.004808333639324454
0.45966188676823216 | 0.008850176067395205
0.4374077134061719 | 0.013775153466815824
0.4348035572373363 | 0.014354729052297408
0.429231432000305 | 0.015597585434425486
0.4026775434158303 | 0.02158148610796228
0.46452543214454 | 0.0077792702707062625
0.44419865077040044 | 0.012267300776881358
0.4057805148303034 | 0.02087629950701537
0.47932026641343045 | 0.0045298539156478565
0.4437991653845059 | 0.012355868365580008
0.4307211517301544 | 0.015264926692322807
0.43502835953898206 | 0.014304666403799574
0.42781031525081714 | 0.015915191782490498
0.47486508329130284 | 0.005507254142513391
0.4683683531614585 | 0.0069341563924203336
0.47079425487655885 | 0.006401096638111146
0.4615282167849287 | 0.00843903939793524
0.464588531846856 | 0.007765386529624119
0.48312266790887265 | 0.0036962408038841784
0.44348683850933046 | 0.012425123763216955
0.4370047807251908 | 0.013864778295491459
0.4620778257770132 | 0.008318010996889115
0.45940707728260594 | 0.0089063275142699
0.47375731433257007 | 0.0057504122271857016
0.4821024007310194 | 0.003919871292797633
0.4500228417848667 | 0.010977807772430608
0.45332236007600146 | 0.01024865262889663
0.45021708798234067 | 0.01093485534131223
0.44856683927582713 | 0.011299872613037764
0.44017931800922433 | 0.013159153006620994
0.44842885136298016 | 0.011330405292652562