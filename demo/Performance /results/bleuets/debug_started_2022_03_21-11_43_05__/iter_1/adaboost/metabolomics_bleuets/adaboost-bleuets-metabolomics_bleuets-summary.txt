Classification on bleuets for metabolomics_bleuets with adaboost.

Database configuration : 
	- Database name : bleuets
	- View name : metabolomics_bleuets	 View shape : (96, 16645)
	- Learning Rate : 0.75
	- Labels used : ["Av2", "Bv2", "Bv4"], ["Av4"]
	- Number of cross validation folds : 7

Classifier configuration : 
	- Adaboost with n_estimators : 66, base_estimator : DecisionTreeClassifier
	- Executed on 4 core(s) 


	For Accuracy score using {}, (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.9166666666666666

	For F1 score using average: micro, {} (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.9166666666666666

	For Balanced accuracy score using {}, (higher is better) : 
		- Score on train : 1.0
		- Score on test : 0.8888888888888888

Test set confusion matrix : 

╒═══════════════════════╤═════════════════════════╤═══════════╕
│                       │   ["Av2", "Bv2", "Bv4"] │   ["Av4"] │
╞═══════════════════════╪═════════════════════════╪═══════════╡
│ ["Av2", "Bv2", "Bv4"] │                      17 │         1 │
├───────────────────────┼─────────────────────────┼───────────┤
│ ["Av4"]               │                       1 │         5 │
╘═══════════════════════╧═════════════════════════╧═══════════╛



 Classification took 0:01:25

 Classifier Interpretation : 
Feature importances : 
- Feature : ID_676, feature importance : 0.20813284126202788
- Feature : ID_2068, feature importance : 0.13401238044664956
- Feature : ID_2060, feature importance : 0.12141043514066595
- Feature : ID_3097, feature importance : 0.07503518174303839
- Feature : ID_3249, feature importance : 0.04667702934015263
- Feature : ID_3013, feature importance : 0.04507570275704062
- Feature : ID_5139, feature importance : 0.04470348739552918
- Feature : ID_2551, feature importance : 0.032521690718654406
- Feature : ID_2396, feature importance : 0.02889887162362895
- Feature : ID_4034, feature importance : 0.017736321420208857
- Feature : ID_2459, feature importance : 0.017709966073080126
- Feature : ID_3879, feature importance : 0.017154769471791533
- Feature : ID_2921, feature importance : 0.016820764435999877
- Feature : ID_266, feature importance : 0.016568322549948094
- Feature : ID_10966, feature importance : 0.016559289354291788
- Feature : ID_3300, feature importance : 0.016297461560972688
- Feature : ID_2946, feature importance : 0.016032023472335306
- Feature : ID_2960, feature importance : 0.015903997921106524
- Feature : ID_3358, feature importance : 0.015758441350685007
- Feature : ID_479, feature importance : 0.015479292250137855
- Feature : ID_3738, feature importance : 0.015330373352210953
- Feature : ID_6222, feature importance : 0.014277690478242781
- Feature : ID_8074, feature importance : 0.01367286245324315
- Feature : ID_2524, feature importance : 0.013634728375265985
- Feature : ID_4747, feature importance : 0.013194867233446967
- Feature : ID_8994, feature importance : 0.01140120781964507


 Estimator error | Estimator weight
0.02777777777777777 | 0.012930512954739556
0.02857142857142857 | 0.012825087630809792
0.014705882352941175 | 0.015292126521912567
0.011194029850746265 | 0.016297461560972688
0.012264150943396222 | 0.015961473221597564
0.03342884431709646 | 0.012235816787297278
0.023797760210803685 | 0.013507802014539909
0.017207929143821167 | 0.01471143668055134
0.017251738048236202 | 0.014702027252952032
0.009708439442879841 | 0.016820764435999877
0.00886410910540567 | 0.017154769471791533
0.007893037411571558 | 0.01758032058235978
0.008509254710514927 | 0.017304661604659825
0.016467751253065595 | 0.014874076533744566
0.016454624586863222 | 0.014877025266533127
0.015334007708901335 | 0.015137691238149438
0.007618735498966076 | 0.017709966073080126
0.013978532939856243 | 0.015479292250137855
0.01676421242686475 | 0.014808088736856363
0.0167692671026167 | 0.014806973616484352
0.016774633416150216 | 0.0148057901067033
0.013948636989981184 | 0.01548718914333371
0.01346885062923951 | 0.015616258282432939
0.014554280665551613 | 0.015330373352210953
0.016860422724380052 | 0.014786920126993272
0.016861986004256233 | 0.014786577148458028
0.01686348420501452 | 0.014786248477396758
0.01632690278563387 | 0.014905837640240484
0.010663207149948967 | 0.016476099906342117
0.013395389468355466 | 0.015636419694619236
0.01683656979666432 | 0.014792157262363386
0.016836134546796444 | 0.014792252893312104
0.010424583280506826 | 0.016559289354291788
0.008506509920647316 | 0.01730584500583368
0.01974812844984577 | 0.014201262509966893
0.01203137393538466 | 0.016032023472335306
0.010344935307755862 | 0.016587476276281637
0.016615620943906756 | 0.014841018280080507
0.009439755150621402 | 0.016923823053819606
0.0075641411334552615 | 0.017736321420208857
0.02588074731234857 | 0.013194867233446967
0.021787990248554587 | 0.013836176533691126
0.020369531090912652 | 0.014086279104290915
0.017026652889093497 | 0.01475062366189443
0.012457070942946614 | 0.015903997921106524
0.01655593628900437 | 0.014854326636680905
0.01036326352070456 | 0.0165809710605465
0.010795882605065548 | 0.016430639496046257
0.01039899227257801 | 0.016568322549948094
0.014821778872455277 | 0.015263148627853452
0.008428450260603747 | 0.017339659444979994
0.019345406362260006 | 0.014277690478242781
0.02300033047531658 | 0.013634728375265985
0.02541635858013707 | 0.013262451929009713
0.02329516844402234 | 0.013587305801389536
0.02276588737442205 | 0.01367286245324315
0.04169226349270501 | 0.01140120781964507
0.026829377985188124 | 0.013060401448787952
0.016372853790007694 | 0.014895446247825957
0.026138422097753165 | 0.013157874117660649
0.014064068527327691 | 0.01545678999919837
0.021306516030934787 | 0.013919236658162318
0.012959146281405853 | 0.015758441350685007
0.007424107495082602 | 0.017804795241595516
0.01924322515595343 | 0.01429733030157399
0.013536206099153868 | 0.015597867664834793